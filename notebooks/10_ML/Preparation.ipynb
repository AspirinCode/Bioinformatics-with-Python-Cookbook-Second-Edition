{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ftp://ngs.sanger.ac.uk/production/ag1000g/phase1/AR3/variation/crosses/ar3/hdf5/ag1000g.crosses.phase1.ar3sites.3L.h5\n",
    "# ftp://ngs.sanger.ac.uk/production/ag1000g/phase1/AR3/variation/crosses/ar3/hdf5/ag1000g.crosses.phase1.ar3sites.3R.h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mendelian simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 100000\n",
    "num_ofs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hets_AA_AT = []\n",
    "for sim in range(num_sims):\n",
    "    sim_hets = 0\n",
    "    for ofs in range(20):\n",
    "        sim_hets += 1 if random.choice([0, 1]) == 1 else 0\n",
    "    num_hets_AA_AT.append(sim_hets)\n",
    "    \n",
    "fig, ax = plt.subplots(1,1, figsize=(16,9))\n",
    "ax.hist(num_hets_AA_AT, bins=range(20))\n",
    "print(len([num_hets for num_hets in num_hets_AA_AT if num_hets==20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_AAs_AT_AT = []\n",
    "num_hets_AT_AT = []\n",
    "for sim in range(num_sims):\n",
    "    sim_AAs = 0\n",
    "    sim_hets = 0\n",
    "    for ofs in range(20):\n",
    "        derived_cnt = sum(random.choices([0, 1], k=2))\n",
    "        sim_AAs += 1 if derived_cnt == 0 else 0\n",
    "        sim_hets += 1 if derived_cnt == 1 else 0\n",
    "    num_AAs_AT_AT.append(sim_AAs)\n",
    "    num_hets_AT_AT.append(sim_hets)\n",
    "fig, ax = plt.subplots(1,1, figsize=(16,9))\n",
    "ax.hist([num_hets_AT_AT, num_AAs_AT_AT], histtype='step', fill=False, bins=range(20), label=['het', 'AA'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_3L = h5py.File('ag1000g.crosses.phase1.ar3sites.3L.h5', 'r')\n",
    "samples_hdf5 = list(map(lambda sample: sample.decode('utf-8'), h5_3L['/3L/samples']))\n",
    "print(samples_hdf5)\n",
    "\n",
    "calldata_genotype = h5_3L['/3L/calldata/genotype']\n",
    "\n",
    "MQ0 = h5_3L['/3L/variants/MQ0']\n",
    "QD = h5_3L['/3L/variants/QD']\n",
    "QUAL = h5_3L['/3L/variants/QUAL']\n",
    "FS = h5_3L['/3L/variants/FS']\n",
    "DP = h5_3L['/3L/variants/DP']\n",
    "HRun = h5_3L['/3L/variants/HRun']\n",
    "ReadPosRankSum = h5_3L['/3L/variants/ReadPosRankSum']\n",
    "my_features = {\n",
    "    'MQ0': MQ0,\n",
    "    'QD': QD,\n",
    "    'QUAL': QUAL,\n",
    "    'FS': FS,\n",
    "    'DP': DP,\n",
    "    'HRun': HRun,\n",
    "    'ReadPosRankSum': ReadPosRankSum\n",
    "}\n",
    "\n",
    "num_alleles = h5_3L['/3L/variants/num_alleles']\n",
    "is_snp = h5_3L['/3L/variants/is_snp']\n",
    "POS = h5_3L['/3L/variants/POS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv('samples.tsv', sep='\\t')\n",
    "print(samples['cross'].unique())\n",
    "print(samples[samples['cross'] == 'cross-29-2'][['id', 'function']])\n",
    "print(len(samples[samples['cross'] == 'cross-29-2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute mendelian errors (biallelic)\n",
    "def compute_mendelian_errors(mother, father, offspring):\n",
    "    num_errors = 0\n",
    "    num_ofs_problems = 0\n",
    "    if len(mother.union(father)) == 1:\n",
    "        # Mother and father are homo and the same\n",
    "        for ofs in offspring:\n",
    "            if len(ofs) == 2:\n",
    "                # Offspring is het\n",
    "                num_errors += 1\n",
    "                num_ofs_problems += 1\n",
    "            elif len(ofs.intersection(mother)) == 0:\n",
    "                # Offspring is homo, but opposite from parents\n",
    "                num_errors += 2\n",
    "                num_ofs_problems += 1\n",
    "    elif len(mother) == 1 and len(father) == 1:\n",
    "        # Mother and father are homo and different\n",
    "        for ofs in offspring:\n",
    "            if len(ofs) == 1:\n",
    "                # Homo, should be het\n",
    "                num_errors += 1\n",
    "                num_ofs_problems += 1\n",
    "    elif len(mother) == 2 and len(father) == 2:\n",
    "        # Both are het, individual offspring can be anything\n",
    "        pass\n",
    "    else:\n",
    "        # One is het, the other is homo\n",
    "        homo = mother if len(mother) == 1 else father\n",
    "        for ofs in offspring:\n",
    "            if len(ofs) == 1 and ofs.intersection(homo):\n",
    "                # homo, but not including the allele from parent that is homo\n",
    "                num_errors += 1\n",
    "                num_ofs_problems += 1\n",
    "    return num_errors, num_ofs_problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceptable_position_to_genotype():\n",
    "    for i, genotype in enumerate(calldata_genotype):\n",
    "        if is_snp[i] and num_alleles[i] == 2:\n",
    "            if len(np.where(genotype == -1)[0]) > 1:\n",
    "                # Missing data\n",
    "                continue\n",
    "            yield i\n",
    "\n",
    "def acumulate(fun):\n",
    "    acumulator = {}\n",
    "    for res in fun():\n",
    "        if res is not None:\n",
    "            acumulator[res[0]] = res[1]\n",
    "    return acumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_family_indexes(samples_hdf5, cross_pd):\n",
    "    offspring = []\n",
    "    for i, individual in cross_pd.T.iteritems():\n",
    "        index = samples_hdf5.index(individual.id)\n",
    "        if individual.function == 'parent':\n",
    "            if individual.sex == 'M':\n",
    "                father = index\n",
    "            else:\n",
    "                mother = index\n",
    "        else:\n",
    "            offspring.append(index)\n",
    "    return {'mother': mother, 'father': father, 'offspring': offspring}\n",
    "\n",
    "cross_pd = samples[samples['cross'] == 'cross-29-2']\n",
    "family_indexes = get_family_indexes(samples_hdf5, cross_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mother_index = family_indexes['mother']\n",
    "father_index = family_indexes['father']\n",
    "offspring_indexes = family_indexes['offspring']\n",
    "all_errors = {}\n",
    "\n",
    "\n",
    "def get_mendelian_errors():\n",
    "    for i in acceptable_position_to_genotype():\n",
    "        genotype = calldata_genotype[i]\n",
    "        mother = set(genotype[mother_index])\n",
    "        father = set(genotype[father_index])\n",
    "        offspring = [set(genotype[ofs_index]) for ofs_index in offspring_indexes]\n",
    "        my_mendelian_errors = compute_mendelian_errors(mother, father, offspring)\n",
    "        yield POS[i], my_mendelian_errors\n",
    "        if i % 100000 == 0:\n",
    "            print(POS[i])\n",
    "        #if i > 100000:\n",
    "        #    break\n",
    "        #if mendelian_errors[0] > 0:\n",
    "        #    #print(POS[i], True, mother, father, offspring)\n",
    "        #    yield POS[i], my_mendelian_errors\n",
    "        #else:\n",
    "        #    yield None\n",
    "\n",
    "mendelian_errors = acumulate(get_mendelian_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mendelian_errors), len(list(filter(lambda x: x[0] > 0,mendelian_errors.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(mendelian_errors, gzip.open('mendelian_errors.pickle.gz', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove\n",
    "mendelian_errors = pickle.load(gzip.open('mendelian_errors.pickle.gz', 'rb'))\n",
    "feature_fit = np.load(gzip.open('feature_fit.npy.gz', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove\n",
    "feature_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_positions = sorted(mendelian_errors.keys())  # Not strictly needed\n",
    "ordered_features = sorted(my_features.keys())\n",
    "num_features = len(ordered_features)\n",
    "feature_fit = np.empty((len(ordered_positions), len(my_features) + 1), dtype=float)\n",
    "for column, feature in enumerate(ordered_features):  # 'Strange' order\n",
    "    print(feature)\n",
    "    current_hdf_row = 0\n",
    "    for row, genomic_position in enumerate(ordered_positions):\n",
    "        if row % 100000 == 0: print(row, POS[current_hdf_row])\n",
    "        while POS[current_hdf_row] < genomic_position:\n",
    "            current_hdf_row +=1\n",
    "        feature_fit[row, column] = my_features[feature][current_hdf_row]\n",
    "for row, genomic_position in enumerate(ordered_positions):\n",
    "    feature_fit[row, num_features] = 1 if mendelian_errors[genomic_position][0] > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(gzip.open('feature_fit.npy.gz', 'wb'), feature_fit, allow_pickle=False, fix_imports=False)\n",
    "pickle.dump(ordered_features, open('ordered_features', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
